{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Q1. What is Simple Linear Regression ?"
      ],
      "metadata": {
        "id": "IqTOaqQnSFPe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Simple Linear Regression is a statistical method that models the relationship between a dependent variable (Y) and a single independent variable (X) using a straight line. The goal is to find the best-fitting line that minimizes the distance between the predicted values and the actual values of Y."
      ],
      "metadata": {
        "id": "BjlWs2ihfmiW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2.  What are the key assumptions of Simple Linear Regression ?"
      ],
      "metadata": {
        "id": "Wq3Qckm4SR0e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Key assumptions include linearity (the relationship between X and Y is linear), independence of errors, homoscedasticity (constant variance of errors), and normally distributed errors."
      ],
      "metadata": {
        "id": "LTICvcngfoW3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3. What does the coefficient m represent in the equation Y=mX+c ?"
      ],
      "metadata": {
        "id": "0RqTMu3LSjf0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the equation Y = mX + c, the coefficient 'm' represents the slope of the line. It indicates the rate of change in Y for a unit change in X."
      ],
      "metadata": {
        "id": "voQ3txe7fumm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q4. What does the intercept c represent in the equation Y=mX+c ?"
      ],
      "metadata": {
        "id": "6x9devuVSpos"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The intercept 'c' represents the value of Y when X is equal to zero. It's the point where the line crosses the Y-axis."
      ],
      "metadata": {
        "id": "gNYfX-Ogfxvt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q5. How do we calculate the slope m in Simple Linear Regression ?"
      ],
      "metadata": {
        "id": "NsQT6Bj0St1U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The slope 'm' is calculated using the least squares method, which minimizes the sum of the squared differences between the observed Y values and the predicted Y values."
      ],
      "metadata": {
        "id": "orH8FjUnf2Yl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q6. What is the purpose of the least squares method in Simple Linear Regression ?"
      ],
      "metadata": {
        "id": "y4RWnvSOSyI0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The least squares method aims to find the line that best fits the data by minimizing the sum of the squared distances between the observed data points and the predicted values on the line."
      ],
      "metadata": {
        "id": "O1c6W-19f7An"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q7.  How is the coefficient of determination (R²) interpreted in Simple Linear Regression ?"
      ],
      "metadata": {
        "id": "SeT-1gB6S3F1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "R-squared represents the proportion of variance in the dependent variable (Y) that is explained by the independent variable (X). A higher R-squared value indicates a better fit of the model to the data."
      ],
      "metadata": {
        "id": "To8UUYYSf-uS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q8. What is Multiple Linear Regression ?"
      ],
      "metadata": {
        "id": "a4C891IeS7rs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multiple Linear Regression is an extension of Simple Linear Regression where the dependent variable (Y) is predicted using multiple independent variables (X1, X2, ..., Xp)."
      ],
      "metadata": {
        "id": "a4leHfFkgDKF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q9. What is the main difference between Simple and Multiple Linear Regression ?"
      ],
      "metadata": {
        "id": "Nf90OTY2TAFN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The main difference lies in the number of independent variables. Simple Linear Regression uses one independent variable, while Multiple Linear Regression uses multiple independent variables."
      ],
      "metadata": {
        "id": "XGql4IdMgvyG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q10. What are the key assumptions of Multiple Linear Regression ?"
      ],
      "metadata": {
        "id": "KgmwTgQoTGCl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Key assumptions include linearity, independence of errors, homoscedasticity, normality of errors, and no multicollinearity (low correlation among independent variables)."
      ],
      "metadata": {
        "id": "exbSDyXogz_2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q11. What is heteroscedasticity, and how does it affect the results of a Multiple Linear Regression model ?"
      ],
      "metadata": {
        "id": "qvURXH1XTJwV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Heteroscedasticity refers to unequal variances of errors. It can lead to biased standard errors of the coefficients, making hypothesis testing unreliable."
      ],
      "metadata": {
        "id": "TRF60i4Ag5KH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q12.  How can you improve a Multiple Linear Regression model with high multicollinearity ?"
      ],
      "metadata": {
        "id": "Emxo5Yq0TOSN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Techniques to address multicollinearity include removing one of the highly correlated variables, using regularization methods, or performing principal component analysis."
      ],
      "metadata": {
        "id": "f9hSpqjIg6xO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q13. What are some common techniques for transforming categorical variables for use in regression models ?"
      ],
      "metadata": {
        "id": "6ulJwPCkTUjE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Common techniques include one-hot encoding, creating dummy variables, and using ordinal encoding for variables with an inherent order."
      ],
      "metadata": {
        "id": "mnmMLam0hBJ1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q14. What is the role of interaction terms in Multiple Linear Regression ?"
      ],
      "metadata": {
        "id": "iRSv1v5jTkHd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interaction terms allow for modeling how the effect of one independent variable on the dependent variable changes depending on the value of another independent variable."
      ],
      "metadata": {
        "id": "orvB1SR2hJ--"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q15. How can the interpretation of intercept differ between Simple and Multiple Linear Regression ?"
      ],
      "metadata": {
        "id": "Dv6yEDkeTpNd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In Simple Linear Regression, the intercept is the value of Y when X is zero. In Multiple Linear Regression, the intercept represents the expected value of Y when all independent variables are zero, which might not always be a realistic scenario."
      ],
      "metadata": {
        "id": "XERXY6wzhSAF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q16. What is the significance of the slope in regression analysis, and how does it affect predictions ?"
      ],
      "metadata": {
        "id": "88tb9wCaTt0V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The slope indicates the direction and strength of the relationship between the independent and dependent variables. It directly influences the predicted values of the dependent variable."
      ],
      "metadata": {
        "id": "tljwLA8ahTMn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q17.  How does the intercept in a regression model provide context for the relationship between variables ?"
      ],
      "metadata": {
        "id": "MUehDNHJT0EV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The intercept provides a baseline value for the dependent variable when the independent variable(s) are at their base level. It helps to understand the starting point of the relationship."
      ],
      "metadata": {
        "id": "DRO5HVQyhYIl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q18. What are the limitations of using R² as a sole measure of model performance ?"
      ],
      "metadata": {
        "id": "InfuiPGeT6gN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "R-squared can increase with the addition of more independent variables, even if they don't improve the model's predictive power. It's important to consider other metrics like adjusted R-squared and cross-validation."
      ],
      "metadata": {
        "id": "nSTm_EjBhbwO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q19.  How would you interpret a large standard error for a regression coefficient ?"
      ],
      "metadata": {
        "id": "T9J-Thb6T-zV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A large standard error suggests that the estimate of the coefficient is not very precise. It implies that the true value of the coefficient could be quite different from the estimated value."
      ],
      "metadata": {
        "id": "OvNJGfB5he79"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q20.  How can heteroscedasticity be identified in residual plots, and why is it important to address it ?"
      ],
      "metadata": {
        "id": "1ZrzMCECUDAc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Heteroscedasticity can be identified by a non-random pattern in the residual plot, such as a funnel shape. Addressing it is important because it can lead to biased standard errors and inaccurate inferences."
      ],
      "metadata": {
        "id": "nCEx-uKnhljY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q21. What does it mean if a Multiple Linear Regression model has a high R² but low adjusted R² ?"
      ],
      "metadata": {
        "id": "FNEorKRLUGuk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This indicates that the model has likely overfitted the data. The high R-squared is likely due to the inclusion of many independent variables that do not significantly improve the model's predictive power."
      ],
      "metadata": {
        "id": "H0IJJHbvhrxN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q22. Why is it important to scale variables in Multiple Linear Regression ?"
      ],
      "metadata": {
        "id": "A_xllPtCULO1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scaling variables helps to ensure that all variables are on a similar scale, which can improve the performance of gradient descent algorithms used in model fitting."
      ],
      "metadata": {
        "id": "eVCD9uUdhvE9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q23. What is polynomial regression ?"
      ],
      "metadata": {
        "id": "gtH2Bu9UUSL1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Polynomial regression models the relationship between the dependent variable and the independent variable using a polynomial function, which allows for capturing non-linear relationships.\n",
        "\n"
      ],
      "metadata": {
        "id": "Z33YqoDUh0YJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q24.  How does polynomial regression differ from linear regression ?"
      ],
      "metadata": {
        "id": "oVsukTRSUbwd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear regression assumes a linear relationship between variables, while polynomial regression allows for more complex, curved relationships.\n",
        "\n"
      ],
      "metadata": {
        "id": "deOYSBEPh6En"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q25.  When is polynomial regression used ?"
      ],
      "metadata": {
        "id": "Bo4fsjWIUgQN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Polynomial regression is used when the relationship between the variables is suspected to be non-linear, such as in cases where a simple linear model does not adequately fit the data.\n",
        "\n"
      ],
      "metadata": {
        "id": "6tiCFxX8h-bS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q26.  What is the general equation for polynomial regression ?"
      ],
      "metadata": {
        "id": "scNlGhYhUkU0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The general equation for a polynomial regression of degree 'd' is Y = b0 + b1X + b2X^2 + ... + bdX^d + error.\n",
        "\n"
      ],
      "metadata": {
        "id": "n-X7BxHXiDAl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q27. Can polynomial regression be applied to multiple variables ?"
      ],
      "metadata": {
        "id": "hBKwyZTYUsOv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, polynomial regression can be extended to multiple variables, resulting in a model with interaction terms between variables and their powers.\n",
        "\n"
      ],
      "metadata": {
        "id": "nKGppvAhiIwH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q28.  What are the limitations of polynomial regression ?"
      ],
      "metadata": {
        "id": "PGwasKoGUxX8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Limitations include the risk of overfitting, difficulty in interpreting higher-order terms, and the potential for numerical instability when dealing with high-degree polynomials."
      ],
      "metadata": {
        "id": "L-ZR000_iNjG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q29. What methods can be used to evaluate model fit when selecting the degree of a polynomial ?"
      ],
      "metadata": {
        "id": "B-iGbQuNU2JE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Methods include cross-validation, using metrics like adjusted R-squared and AIC/BIC, and examining residual plots to check for patterns."
      ],
      "metadata": {
        "id": "mzAXu1NDiTAl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q30. Why is visualization important in polynomial regression ?"
      ],
      "metadata": {
        "id": "kO7xOXkxU7Z0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualization helps to understand the shape of the relationship between variables, identify potential non-linearities, and evaluate the fit of different polynomial models."
      ],
      "metadata": {
        "id": "YjzejMsYiW52"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q31. How is polynomial regression implemented in Python ?"
      ],
      "metadata": {
        "id": "Mjf5KP1XVAMd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Polynomial regression can be implemented in Python using libraries like scikit-learn, where you can create polynomial features using the PolynomialFeatures class and then fit a linear regression model."
      ],
      "metadata": {
        "id": "s2pkXriAicel"
      }
    }
  ]
}